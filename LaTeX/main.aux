\relax 
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Learning Method and Regression Model}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}State representation}{2}}
\citation{paper}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Rewards}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Regressors}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces For this figure, {\fontfamily  {pcr}\selectfont  sklearn.datasets.make\_regression} was used to create $10000$ samples with $100$ features of which $10$ are informative. We then trained the Random Forest Regressor and the MLP-Regressor provided by \textit  {scikit-learn} with $80\%$ of the generated data. The figure shows the predicted values of the remaining $20\%$ of the data which were used as a test set. The test set has previously been sorted by the true value in ascending order.}}{5}}
\newlabel{forest_mlp_comp1}{{1}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Training Process}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces For this figure, {\fontfamily  {pcr}\selectfont  sklearn.datasets.make\_regression} was used to create $10000$ samples with $100$ features of which $10$ are informative. We then trained the Random Forest Regressor and the MLP-Regressor provided by \textit  {scikit-learn} with $80\%$ of the generated data. The figure shows the predicted values of the remaining $20\%$ of the data which were used as a test set. The test set has previously been sorted by the true value in ascending order.}}{6}}
\newlabel{forest_mlp_comp2}{{2}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Q-Learning}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Exploration and exploitation}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Training data}{8}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Results}{8}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Heins thoughts}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}State representation}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Rewards}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Estimator}{10}}
\citation{paper}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Learning algorithm}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Necessary functions}{12}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Karls thoughts}{12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Neural Networks}{13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Classical approach}{14}}
\@writefile{toc}{\contentsline {subsubsection}{State appraisal}{14}}
\@writefile{toc}{\contentsline {subsubsection}{Rewards}{15}}
\@writefile{toc}{\contentsline {subsubsection}{Exploration vs. Exploitation}{15}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Karls observations}{16}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}The state matrix}{16}}
\bibcite{RL_intro}{1}
\bibcite{paper}{2}
