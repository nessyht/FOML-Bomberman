\relax 
\babel@aux{english}{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Learning Method and Regression Model}{2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}State representation}{2}\protected@file@percent }
\citation{paper}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Rewards}{4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Regressors}{5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Training Process}{6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces For this figure, {\fontfamily  {pcr}\selectfont  sklearn.datasets.make\_regression} was used to create $10000$ samples with $100$ features of which $10$ are informative. We then trained the Random Forest Regressor and the MLP-Regressor provided by \textit  {scikit-learn} with $80\%$ of the generated data. The figure shows the predicted values of the remaining $20\%$ of the data which were used as a test set. The test set has previously been sorted by the true target value in ascending order.}}{7}\protected@file@percent }
\newlabel{forest_mlp_comp1}{{1}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces This figure displays the same data as Figure \ref  {forest_mlp_comp1}. Here, the x-axis represents the position of each instance sorted by its target value, the y-axis displays the position if the instances had been sorted by the predicted target values of the respective regressor. The more the predictions resemble the correct order (the green line) the better the regressor is suited for our task.}}{8}\protected@file@percent }
\newlabel{forest_mlp_comp2}{{2}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Q-Learning}{8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Exploration and exploitation}{9}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Training data}{9}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Results}{10}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Heins thoughts}{10}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}State representation}{10}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Rewards}{11}\protected@file@percent }
\citation{paper}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Estimator}{12}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Learning algorithm}{12}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Necessary functions}{13}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Karls thoughts}{14}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Neural Networks}{14}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Classical approach}{15}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{State appraisal}{15}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Rewards}{16}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Exploration vs. Exploitation}{17}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}Karls observations}{17}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}The state matrix}{17}\protected@file@percent }
\bibcite{RL_intro}{1}
\bibcite{paper}{2}
