\relax 
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Learning Method and Regression Model}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}State representation}{2}}
\@writefile{toc}{\contentsline {subsubsection}{State representation 1}{2}}
\citation{paper}
\@writefile{toc}{\contentsline {subsubsection}{State representation 2}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Rewards}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Regressors}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces \textit  {For this figure, {\normalfont  {\fontfamily  {pcr}\selectfont  sklearn.datasets.make\_regression}} was used to create $10000$ samples with $100$ features of which $10$ are informative. We then trained the Random Forest Regressor and the MLP-Regressor provided by {\normalfont  scikit-learn} with $80\%$ of the generated data. The figure shows the predicted values of the remaining $20\%$ of the data which were used as a test set. The test set has previously been sorted by the true target value in ascending order.}}}{7}}
\newlabel{forest_mlp_comp1}{{1}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces \textit  {This figure displays the same data as Figure \ref  {forest_mlp_comp1}. Here, the x-axis represents the position of each instance sorted by its target value, the y-axis displays the position if the instances had been sorted by the predicted target values of the respective regressor. The more the predictions resemble the correct order (the green line) the better the regressor is suited for our task.}}}{8}}
\newlabel{forest_mlp_comp2}{{2}{8}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Training Process}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Q-Learning}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Exploration and exploitation}{10}}
\@writefile{toc}{\contentsline {subsubsection}{Max-Boltzman-exploration}{10}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces \textit  {Exemplary table of expected rewards $Q(s,a)$ and corresponding probabilities $\pi (s,a)$ if $T$ is chosen as described above. In this case: $T=30.4$}}}{11}}
\newlabel{MB_table}{{3}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Training data}{11}}
\citation{paper}
\@writefile{toc}{\contentsline {section}{\numberline {3}Results}{12}}
\newlabel{results}{{3}{12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}The initial approach}{12}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Here we see the performance of 40 generations trained with the random forest and 8 generations using the MLP. We chose not to train the MLP further as the time constraints were too severe and we were not seeing any improvement.}}{13}}
\newlabel{mlp_vs_forest_gamma_1.0}{{4}{13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Outlook}{13}}
\@writefile{toc}{\contentsline {subsubsection}{State Representation}{14}}
\@writefile{toc}{\contentsline {subsubsection}{Reward Scheme}{14}}
\@writefile{toc}{\contentsline {subsubsection}{Regressors}{14}}
\@writefile{toc}{\contentsline {subsubsection}{Training procedure}{15}}
\@writefile{toc}{\contentsline {subsubsection}{Exploration / Exploitation}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Further Comments on the final project}{15}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Heins thoughts}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}State representation}{16}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Rewards}{17}}
\citation{paper}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Estimator}{18}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Learning algorithm}{18}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Necessary functions}{19}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Karls thoughts}{20}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Neural Networks}{20}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Classical approach}{21}}
\@writefile{toc}{\contentsline {subsubsection}{State appraisal}{21}}
\@writefile{toc}{\contentsline {subsubsection}{Rewards}{22}}
\@writefile{toc}{\contentsline {subsubsection}{Exploration vs. Exploitation}{23}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Karls observations}{23}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}The state matrix}{23}}
\bibcite{RL_intro}{1}
\bibcite{paper}{2}
